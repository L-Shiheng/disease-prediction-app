import io
import os
import joblib
import torch
import numpy as np
import pandas as pd
import streamlit as st
import pyopenms as oms
import torch.nn as nn
import tempfile  # <---ã€æ–°å¢ 1ã€‘å¿…é¡»å¼•å…¥è¿™ä¸ªåº“æ¥å¤„ç†äº‘ç«¯æ–‡ä»¶
from jcamp import jcamp_readfile
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from torch.utils.data import Dataset, DataLoader

# ==========================================
# 1. å¿…é¡»åŒ…å«çš„æ¨¡å‹ç±»å®šä¹‰ (ä¿æŒä¸å˜)
# ==========================================
class BiLSTM(nn.Module):
    def __init__(self, input_size,hidden_size,num_layers,num_classes,BiDirection=True):
        super(BiLSTM, self).__init__()
        self.layer_norm = nn.LayerNorm(input_size) 
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.BiDirection = BiDirection
        self.lstm = nn.LSTM(input_size,hidden_size,num_layers,dropout=0.3,batch_first=True,bidirectional=BiDirection)        
        # å…¨è¿æ¥è¾“å‡ºå±‚
        if self.BiDirection == True:
            self.fc = nn.Linear(hidden_size*2,num_classes)
        else:
            self.fc = nn.Linear(hidden_size,num_classes)

    def forward(self, x):
        # åˆå§‹åŒ–éšè—çŠ¶æ€å’Œç»†èƒçŠ¶æ€
        if self.BiDirection == True:
            hc0 = self.num_layers*2
        else:
            hc0 = self.num_layers
        h0 = torch.zeros(hc0, x.size(0), self.hidden_size).to(x.device)
        c0 = torch.zeros(hc0, x.size(0), self.hidden_size).to(x.device)
        
        # LSTMå‰å‘ä¼ æ’­
        out, (h_n,c_n) = self.lstm(x, (h0, c0))
        
        # å…¨è¿æ¥å±‚é¢„æµ‹
        out = self.fc(out[:, -1, :])
        
        return out

# ==========================================
# 2. æ¨¡å‹é¢„å¤„ç†ç±»å®šä¹‰
# ==========================================
class Data_prepossing:
    def __init__(self,tolerance:float=0.5,SEQ_LENGTH:int=3,SEQ_SIZE:int=80):
        super(Data_prepossing, self).__init__()
        self.tolerance = tolerance
        self.seq_length = SEQ_LENGTH
        self.seq_size = SEQ_SIZE
    
    # æ•°æ®è´¨æ§ï¼Œè´¨è°±å³°å»å™ªï¼Œå»å¹³å¤´å³°
    def noise_removal(self,mass_list,tolerance=0.5):
        total = mass_list.tolist()
        if len(total) == 0: return [] # é˜²æ­¢ç©ºæ•°æ®æŠ¥é”™
        ref_total = total[1:]+[[0,0]]
        new_total = [[r[0]-m[0],r[1]-m[1]] for r,m in zip(ref_total,total)]
        tf = [total[0]]
        for new,ref,to in zip(new_total,ref_total,total):
            if new[0] >= tolerance:
                tf = tf+[ref]
            else:
                if new[1]>=0:
                    tf = tf[:-1]+[ref]+[ref]
                else:
                    tf = tf[:-1]+[to]+[to]
        tf = [m for i,m in enumerate(tf) if m not in tf[:i]]
        return tf

    # ç”Ÿæˆopenmsæ•°æ®æ ¼å¼
    def openms_data_format(self,mass,intensity,decimal=5):
        # è´¨è°±ä¿ç•™
        mz = np.round(mass.values,decimal)
        mz_intensity = intensity.values
        spectrum = oms.MSSpectrum()
        spectrum.set_peaks([mz,mz_intensity])
        spectrum.sortByPosition()
        return spectrum

    # è´¨é‡æ•°å¯¹é½
    def mass_align(self,ref_spectrum,obs_spectrum,tolerance=0.5):
        alignment = []
        spa = oms.SpectrumAlignment()
        p = spa.getParameters()
        p.setValue("tolerance", tolerance)
        p.setValue("is_relative_tolerance", "false")
        spa.setParameters(p)
        spa.getSpectrumAlignment(alignment, ref_spectrum, obs_spectrum)
        return alignment

    # æŒ‰å‚æ¯”æ–‡ä»¶_2
    def mass_calculation_ref(self,re_spectrum,ob_spectrum,alignment,decimal=4):
        ref = [i[0] for i in alignment]
        obs = [j[1] for j in alignment]
        for i,j in zip(ref,obs):
            # å¢åŠ è¶Šç•Œæ£€æŸ¥ï¼Œé˜²æ­¢æŠ¥é”™
            if i < len(re_spectrum) and j < len(ob_spectrum):
                ob_spectrum.iloc[j, 0] = re_spectrum.iloc[i, 0]
        return re_spectrum,ob_spectrum
    
    def load_imputer(self):
        # ä½ çš„é¢„å¤„ç†æ¨¡å‹è·¯å¾„ (ç›¸å¯¹è·¯å¾„)
        scaler_path = r'imputer_scaler_model.pkl' 
        if not os.path.exists(scaler_path):
            st.error(f"âŒ æ‰¾ä¸åˆ°é¢„å¤„ç†æ–‡ä»¶ï¼š{scaler_path}")
            return None
        try:
            scaler = joblib.load(scaler_path)
            return scaler
        except Exception as e:
            st.error(f"é¢„å¤„ç†å™¨åŠ è½½å‡ºé”™: {e}")
            return None
    
    # æ•°æ®å¯¹é½å’Œæ•´åˆ
    def prediction_pretreatment(self,uploaded_files,ages:list[int],genders:list[int]):
        # ä¸Šä¼ å‚æ¯”æ•°æ®
        sample_name = []
        # ç¡®ä¿ train_target.xlsx åœ¨ GitHub ä»“åº“é‡Œ
        if not os.path.exists('train_target.xlsx'):
            st.error("âŒ æ‰¾ä¸åˆ° train_target.xlsx")
            return None, None
            
        thyroid_train = pd.read_excel('train_target.xlsx')
        prim = thyroid_train.iloc[:,0:2]
        
        DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
        
        # æ•°æ®å¯¹é½
        for i, file in enumerate(uploaded_files):
            # ---ã€æ–°å¢ 2ã€‘åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¤„ç†é€»è¾‘ ---
            # Streamlit çš„ file å¯¹è±¡åœ¨å†…å­˜ä¸­ï¼Œjcamp éœ€è¦ç‰©ç†è·¯å¾„
            with tempfile.NamedTemporaryFile(delete=False, suffix=".jdx") as tmp_file:
                tmp_file.write(file.getvalue())
                tmp_file_path = tmp_file.name
            
            try:
                # è¯»å–ä¸´æ—¶æ–‡ä»¶è·¯å¾„
                jdxfile = jcamp_readfile(tmp_file_path) 
                
                indata = np.vstack((jdxfile['x'],jdxfile['y'])).T
                denoise = self.noise_removal(indata,tolerance=self.tolerance) # å»é™¤å™ªå£°
                framefile = pd.DataFrame(denoise,columns=['mass',file.name])
                sample_name.append(file.name)
                
                # æ•°æ®éªŒè¯
                ref_spectrum = self.openms_data_format(prim.mass,prim.iloc[:,1])
                obs_spectrum = self.openms_data_format(framefile.mass,framefile.iloc[:,1])
                alignment = self.mass_align(ref_spectrum,obs_spectrum,tolerance=self.tolerance)
                
                # æ•°æ®æ•´åˆ
                r_spectrum,o_spectrum = self.mass_calculation_ref(prim,framefile,alignment)
                prim = pd.merge(prim,o_spectrum,how='left',on='mass') 
                
            finally:
                # å¿…é¡»åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                os.remove(tmp_file_path)
            # -----------------------------------
        
        # åˆ å»è¾…åŠ©æ•°æ®
        prediction = prim.drop(prim.columns[1], axis=1).iloc[:,1:].T
        
        # å¡«å……å¯èƒ½äº§ç”Ÿçš„ NaN (merge left å¯èƒ½ä¼šäº§ç”Ÿç©ºå€¼)
        prediction = prediction.fillna(0)
        
        scaler = self.load_imputer()
        prediction = scaler.transform(prediction)
        
        # å¹´é¾„å’Œæ€§åˆ«æ•°æ®æ•´åˆ
        buckets=[0,20,40,60,80]  
        age_bucket = np.digitize(ages, buckets, right=False) - 1
        
        # ---ã€æ–°å¢ 3ã€‘ä¿®å¤æ€§åˆ«é€»è¾‘ ---
        # ä½ çš„ UI ä¼ è¿›æ¥çš„æ˜¯æ•°å­— 1(ç”·) æˆ– 0(å¥³)ï¼Œä¸æ˜¯å­—ç¬¦ä¸² 'male'
        # åŸä»£ç ï¼šif m == 'male' (æ°¸è¿œä¸º False)
        # ä¿®æ”¹ä¸ºï¼šif m == 1
        categoricals = np.array([[0,1] if m == 1 else [1,0] for m in genders]).T
        
        totals = np.vstack((prediction.T,age_bucket.astype('float32'),categoricals))
        
        # è½¬æ¢ä¸ºtensorï¼Œå¹¶åœ¨Deviceä¸Šè¿è¡Œ
        prediction_tensor = torch.tensor(totals.T,dtype=torch.float32)
        prediction_seq = prediction_tensor.view(-1,self.seq_length,self.seq_size).to(DEVICE)
        
        return prediction_seq,sample_name

# ==========================================
# 3. stremlitç•Œé¢åŠæ¨¡å‹ä¸Šè½½
# ==========================================
@st.cache_resource
def load_deep_model():
    model_path = r'PDD.pth'  # ä¿æŒç›¸å¯¹è·¯å¾„ï¼Œä¸è¦å†™ D:\
    if not os.path.exists(model_path):
        st.error(f"âŒ æ‰¾ä¸åˆ° LSTM æ¨¡å‹æ–‡ä»¶ï¼š{model_path}")
        return None
    try:
        # weights_only=False è§£å†³ç‰ˆæœ¬å…¼å®¹æ€§æŠ¥é”™
        model = torch.load(model_path, map_location='cpu', weights_only=False)
        model.eval()
        return model
    except Exception as e:
        st.error(f"LSTM æ¨¡å‹åŠ è½½å‡ºé”™: {e}")
        return None

# Streamlitç•Œé¢
st.title("åŸºäºDPiMSå’Œæ·±åº¦å­¦ä¹ çš„ç‰™å‘¨ç—…è¯Šæ–­ç³»ç»Ÿ")
uploaded_files = st.file_uploader("å¯ä»¥ä¸Šä¼ å¤šä¸ªJDXæ–‡ä»¶", type=["jdx", "dx"], accept_multiple_files=True)
ages = []
genders = []

if uploaded_files:
    # åŠ è½½å¹´é¾„å’Œæ€§åˆ«æ•°æ®
    for i, file in enumerate(uploaded_files):
        st.subheader(f"æ–‡ä»¶ {i+1}: {file.name}")
        age = st.number_input(f"è¾“å…¥å¹´é¾„ ({file.name})", min_value=0, max_value=120, value=25, key=f"age_{i}")
        # è¿™é‡Œ 1=ç”·, 0=å¥³
        gender = st.selectbox(f"é€‰æ‹©æ€§åˆ« ({file.name})", options=[0, 1], format_func=lambda x: "ç”·" if x == 1 else "å¥³", key=f"gender_{i}")
        ages.append(age)
        genders.append(gender)

    if st.button("å¼€å§‹è®­ç»ƒå¹¶é¢„æµ‹"):
        # æ•°æ®é¢„å¤„ç†
        prepossessor = Data_prepossing(SEQ_LENGTH=3,SEQ_SIZE=80)
        
        # è°ƒç”¨å¤„ç†å‡½æ•°
        input_tensor, col_name = prepossessor.prediction_pretreatment(uploaded_files, ages, genders)
        
        if input_tensor is not None:
            DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
            
            # åˆå§‹åŒ–åŠ è½½
            model = load_deep_model()
            if model:
                model = model.to(DEVICE)

                # é¢„æµ‹
                with torch.no_grad():
                    output = model(input_tensor)
                    probabilities = torch.softmax(output, dim=1)
                    predicted_class = torch.argmax(probabilities, dim=1)
                    confidence = torch.max(probabilities, dim=1)[0].cpu()

                # ==========================================
                # 5. ç»“æœå±•ç¤º
                # ==========================================
                st.divider()
                st.subheader("ğŸ”® åˆ†ææŠ¥å‘Š")
                group_name = ['å¥åº·','ç‰™å‘¨ç‚+ç³–å°¿ç—…','ç‰™å‘¨ç‚']
                for col,m,n in zip(col_name,predicted_class,confidence):
                    col1, col2, col3 = st.columns(3)
                    col1.metric("æ ·å“åç§°", f"{col}")
                    col2.metric("é¢„æµ‹ç±»åˆ«", f"{group_name[m]}")
                    col3.metric("ç½®ä¿¡åº¦", f"{n.item():.1%}")
